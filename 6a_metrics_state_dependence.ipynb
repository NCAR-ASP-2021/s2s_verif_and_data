{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "86fbc23c-6f89-407d-b074-452cfda56fec",
   "metadata": {},
   "source": [
    "# Calculate metrics using climpred\n",
    "\n",
    "---\n",
    "\n",
    "Now that all of our model and observational data is ready for analysis, we can run this notebook and calculate various metrics using climpred across all models and seasons and compare how they do. It is recommended that you use `dask` to run this notebook as we are looking at geospatial data and making maps. You can start up a `dask` cluster by running the notebook `cluster.ipynb` and copying the Scheduler tcp number into this notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1256f7d8-8da0-42c2-b6c8-dcbd4ce59258",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<dask.config.set at 0x2b741dee5400>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import cftime\n",
    "import numpy as np\n",
    "import xarray as xr\n",
    "import pandas as pd\n",
    "xr.set_options(keep_attrs=True)\n",
    "import climpred\n",
    "import intake\n",
    "from tqdm import tqdm\n",
    "import dask.array as da\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.ticker import FixedLocator\n",
    "import xskillscore as xs\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "from dask.distributed import Client\n",
    "import dask.config\n",
    "dask.config.set({\"array.slicing.split_large_chunks\": False})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2c56bc3e-5602-488e-96b7-97b6ec9660d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: intake-xarray in /glade/u/home/berner/.local/lib/python3.9/site-packages (0.5.0)\n",
      "Requirement already satisfied: dask>=2.2 in /glade/u/ssg/ch/usr/jupyterhub.hpc.ucar.edu/jupyterhub-20210616/lib/python3.9/site-packages (from intake-xarray) (2021.6.0)\n",
      "Requirement already satisfied: intake>=0.5.2 in /glade/u/home/berner/.local/lib/python3.9/site-packages (from intake-xarray) (0.6.2)\n",
      "Requirement already satisfied: xarray>=0.17.0 in /glade/u/home/berner/.local/lib/python3.9/site-packages (from intake-xarray) (0.18.2)\n",
      "Requirement already satisfied: requests in /glade/u/ssg/ch/usr/jupyterhub.hpc.ucar.edu/jupyterhub-20210616/lib/python3.9/site-packages (from intake-xarray) (2.25.1)\n",
      "Requirement already satisfied: netcdf4 in /glade/u/home/berner/.local/lib/python3.9/site-packages (from intake-xarray) (1.5.7)\n",
      "Requirement already satisfied: msgpack in /glade/u/ssg/ch/usr/jupyterhub.hpc.ucar.edu/jupyterhub-20210616/lib/python3.9/site-packages (from intake-xarray) (1.0.2)\n",
      "Requirement already satisfied: fsspec>0.8.3 in /glade/u/ssg/ch/usr/jupyterhub.hpc.ucar.edu/jupyterhub-20210616/lib/python3.9/site-packages (from intake-xarray) (2021.6.0)\n",
      "Requirement already satisfied: zarr in /glade/u/home/berner/.local/lib/python3.9/site-packages (from intake-xarray) (2.8.3)\n",
      "Requirement already satisfied: partd>=0.3.10 in /glade/u/ssg/ch/usr/jupyterhub.hpc.ucar.edu/jupyterhub-20210616/lib/python3.9/site-packages (from dask>=2.2->intake-xarray) (1.2.0)\n",
      "Requirement already satisfied: cloudpickle>=1.1.1 in /glade/u/ssg/ch/usr/jupyterhub.hpc.ucar.edu/jupyterhub-20210616/lib/python3.9/site-packages (from dask>=2.2->intake-xarray) (1.6.0)\n",
      "Requirement already satisfied: pyyaml in /glade/u/ssg/ch/usr/jupyterhub.hpc.ucar.edu/jupyterhub-20210616/lib/python3.9/site-packages (from dask>=2.2->intake-xarray) (5.4.1)\n",
      "Requirement already satisfied: toolz>=0.8.2 in /glade/u/ssg/ch/usr/jupyterhub.hpc.ucar.edu/jupyterhub-20210616/lib/python3.9/site-packages (from dask>=2.2->intake-xarray) (0.11.1)\n",
      "Requirement already satisfied: appdirs in /glade/u/home/berner/.local/lib/python3.9/site-packages (from intake>=0.5.2->intake-xarray) (1.4.4)\n",
      "Requirement already satisfied: jinja2 in /glade/u/ssg/ch/usr/jupyterhub.hpc.ucar.edu/jupyterhub-20210616/lib/python3.9/site-packages (from intake>=0.5.2->intake-xarray) (3.0.1)\n",
      "Requirement already satisfied: entrypoints in /glade/u/ssg/ch/usr/jupyterhub.hpc.ucar.edu/jupyterhub-20210616/lib/python3.9/site-packages (from intake>=0.5.2->intake-xarray) (0.3)\n",
      "Requirement already satisfied: locket in /glade/u/ssg/ch/usr/jupyterhub.hpc.ucar.edu/jupyterhub-20210616/lib/python3.9/site-packages (from partd>=0.3.10->dask>=2.2->intake-xarray) (0.2.0)\n",
      "Requirement already satisfied: pandas>=1.0 in /glade/u/ssg/ch/usr/jupyterhub.hpc.ucar.edu/jupyterhub-20210616/lib/python3.9/site-packages (from xarray>=0.17.0->intake-xarray) (1.2.4)\n",
      "Requirement already satisfied: setuptools>=40.4 in /glade/u/ssg/ch/usr/jupyterhub.hpc.ucar.edu/jupyterhub-20210616/lib/python3.9/site-packages (from xarray>=0.17.0->intake-xarray) (49.6.0.post20210108)\n",
      "Requirement already satisfied: numpy>=1.17 in /glade/u/ssg/ch/usr/jupyterhub.hpc.ucar.edu/jupyterhub-20210616/lib/python3.9/site-packages (from xarray>=0.17.0->intake-xarray) (1.20.3)\n",
      "Requirement already satisfied: python-dateutil>=2.7.3 in /glade/u/ssg/ch/usr/jupyterhub.hpc.ucar.edu/jupyterhub-20210616/lib/python3.9/site-packages (from pandas>=1.0->xarray>=0.17.0->intake-xarray) (2.8.1)\n",
      "Requirement already satisfied: pytz>=2017.3 in /glade/u/ssg/ch/usr/jupyterhub.hpc.ucar.edu/jupyterhub-20210616/lib/python3.9/site-packages (from pandas>=1.0->xarray>=0.17.0->intake-xarray) (2021.1)\n",
      "Requirement already satisfied: six>=1.5 in /glade/u/ssg/ch/usr/jupyterhub.hpc.ucar.edu/jupyterhub-20210616/lib/python3.9/site-packages (from python-dateutil>=2.7.3->pandas>=1.0->xarray>=0.17.0->intake-xarray) (1.16.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /glade/u/ssg/ch/usr/jupyterhub.hpc.ucar.edu/jupyterhub-20210616/lib/python3.9/site-packages (from jinja2->intake>=0.5.2->intake-xarray) (2.0.1)\n",
      "Requirement already satisfied: cftime in /glade/u/home/berner/.local/lib/python3.9/site-packages (from netcdf4->intake-xarray) (1.5.0)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /glade/u/ssg/ch/usr/jupyterhub.hpc.ucar.edu/jupyterhub-20210616/lib/python3.9/site-packages (from requests->intake-xarray) (1.26.5)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /glade/u/ssg/ch/usr/jupyterhub.hpc.ucar.edu/jupyterhub-20210616/lib/python3.9/site-packages (from requests->intake-xarray) (2021.5.30)\n",
      "Requirement already satisfied: chardet<5,>=3.0.2 in /glade/u/ssg/ch/usr/jupyterhub.hpc.ucar.edu/jupyterhub-20210616/lib/python3.9/site-packages (from requests->intake-xarray) (4.0.0)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /glade/u/ssg/ch/usr/jupyterhub.hpc.ucar.edu/jupyterhub-20210616/lib/python3.9/site-packages (from requests->intake-xarray) (2.10)\n",
      "Requirement already satisfied: numcodecs>=0.6.4 in /glade/u/home/berner/.local/lib/python3.9/site-packages (from zarr->intake-xarray) (0.8.0)\n",
      "Requirement already satisfied: fasteners in /glade/u/home/berner/.local/lib/python3.9/site-packages (from zarr->intake-xarray) (0.16.3)\n",
      "Requirement already satisfied: asciitree in /glade/u/home/berner/.local/lib/python3.9/site-packages (from zarr->intake-xarray) (0.3.3)\n"
     ]
    }
   ],
   "source": [
    "# Additional schnickschnack for state-dependence\n",
    "#conda install -c conda-forge xesmf\n",
    "! pip install intake-xarray"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9984a65-454b-4851-8bce-eac94b9c1cf9",
   "metadata": {},
   "source": [
    "- Make sure you have copied the correct tcp here from the `cluster.ipynb` notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bec8e1b7-a7f6-4390-a59d-ebe6df7ab22d",
   "metadata": {},
   "outputs": [],
   "source": [
    "client = Client(\"tcp://10.12.206.46:46659\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67561ea5-8233-4b72-9c7f-ee4b960d24bd",
   "metadata": {},
   "source": [
    "## Here is where you choose your variable, metric and start/end time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2f37dbda-41c3-40f8-a98a-19e53da1be0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "variable = \"t2m\" #can be t2m, tp, gh_500\n",
    "metric = \"acc\" #can be rps, rmse, acc\n",
    "data = \"anom\"\n",
    "lead = \"daily\" #biweekly or daily\n",
    "area = \"geospatial\"\n",
    "start = \"1999-01-01\"\n",
    "end = \"2020-12-31\" \n",
    "models = [\"ECMWF\",\"NCEP\",\"ECCC\"] #this notebook uses all three of these models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6f292d15-abd7-4573-871d-a14669c13cee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here we are just setting options for the different metrics and mapping.\n",
    "if metric == \"acc\":\n",
    "    comp=\"e2o\"; dim=\"init\"; ens=\"ensmean\" #options for metrics\n",
    "    cmap=\"RdBu_r\" #options for maps\n",
    "elif metric==\"rmse\":\n",
    "    comp=\"e2o\"; dim=\"init\"; ens=\"ensmean\" #options for metrics\n",
    "    cmap=\"viridis\" #options for maps\n",
    "elif metric==\"rps\":\n",
    "    comp=\"m2o\"; dim=[\"init\",\"member\"]; ens=\"\" #options for metrics\n",
    "    cmap=\"viridis\" #options for maps"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "142ab702-5777-4f31-b8f7-233010a324dd",
   "metadata": {},
   "source": [
    "## Now we read in and load the data into `dask`\n",
    "\n",
    "We are using the intake catalog to find the data and load it up. Make sure you have the file `ASP_data_catalog.yml` in your local directory. Or you can find it here: `/glade/campaign/mmm/c3we/jaye/S2S_zarr/`\n",
    "\n",
    "We have an `if` statement here telling us to load in category_edge files, only if our metric of choice is `rps`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ac0a25d2-f88c-4dab-8832-41514ba6dc37",
   "metadata": {},
   "outputs": [],
   "source": [
    "cat = intake.open_catalog('ASP_data_catalog.yml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5f86f8f1-e420-404e-a692-4fa6ae23d7bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "hinds = {}\n",
    "for m in models:\n",
    "    hinds[m] = cat[m](data=data, lead=lead, dim=area).to_dask().astype('float32')\n",
    "verif = cat['OBS'](data=data, lead=lead, dim=area).to_dask().astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4b1a30c8-eeed-4511-ab6f-68100874088e",
   "metadata": {},
   "outputs": [],
   "source": [
    "if metric == \"rps\":\n",
    "    hinds_edges = {}\n",
    "    for m in models:\n",
    "        hinds_edges[m] = cat['cat_edges'](data=data, model=m, lead=lead, dim=area).to_dask().astype('float32') \\\n",
    "                         .chunk({\"category_edge\": -1, \"dayofyear\": -1, \"lat\": 45, \"lead\": -1, \"lon\": 60}).persist()\n",
    "    verif_edges = cat['cat_edges'](data='anom', model='OBS', lead='biweekly', dim='geospatial').to_dask().astype('float32') \\\n",
    "                  .chunk({\"category_edge\": -1, \"dayofyear\": -1, \"lat\": 45, \"lon\": 60}).persist()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4abbbe09-3f80-4b34-894b-ff98160d263b",
   "metadata": {},
   "source": [
    "- All of the model data is now loaded into a dictionary so that we can have them all together for comparison purposes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ad41ef1f-1d69-458d-a644-be9b9674e430",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['DJF', 'MAM', 'JJA', 'SON'], dtype='object', name='init') freq = None\n",
      "Index(['DJF', 'MAM', 'JJA', 'SON'], dtype='object', name='init') freq = None\n",
      "Index(['DJF', 'MAM', 'JJA', 'SON'], dtype='object', name='init') freq = None\n"
     ]
    }
   ],
   "source": [
    "# is seasonal data available for all models and rechunk\n",
    "for h in hinds:\n",
    "    print(hinds[h].init.dt.season.to_index().unique(), 'freq =',hinds[h].init.to_index().freq) # freq would show weekly but calendar conversion breaks this\n",
    "    hinds[h] = hinds[h].chunk({\"member\": \"auto\", \"init\": -1, \"lead\": \"auto\", \"lat\": 45, \"lon\": 60}).persist()\n",
    "    hinds[h] = hinds[h].sel(init=slice(start,end))\n",
    "verif = verif.sel(time=slice(start,end))\n",
    "verif = verif.chunk({\"time\": -1, \"lat\": 45, \"lon\": 60})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "054807b8-24f4-41a8-b264-7bceb0273cd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Read in labels containing classification of projection onto large-scale pattern indexes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4d6314d1-a558-41f7-9d30-e2691b3c9677",
   "metadata": {},
   "outputs": [],
   "source": [
    "nao_pos=xr.open_dataset(\"/glade/u/home/berner/ASP2021_tutorials/s2s_verif_and_data/data/indexfield_NAO_pos.nc\")\n",
    "nao_neg=xr.open_dataset(\"/glade/u/home/berner/ASP2021_tutorials/s2s_verif_and_data/data/indexfield_NAO_neg.nc\")   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "724c0c02-8dcb-408c-b294-20df02e04dc5",
   "metadata": {},
   "outputs": [],
   "source": [
    " #nao_plus has dimension \"time\" and hinds has dimension \"init\"; here we map on onto the other\n",
    "nao_pos[\"init\"] = [cftime.DatetimeProlepticGregorian(pd.DatetimeIndex([d]).year[0], pd.DatetimeIndex([d]).month[0], pd.DatetimeIndex([d]).day[0]) for d in nao_pos.time.values]      \n",
    "nao_neg[\"init\"] = [cftime.DatetimeProlepticGregorian(pd.DatetimeIndex([d]).year[0], pd.DatetimeIndex([d]).month[0], pd.DatetimeIndex([d]).day[0]) for d in nao_neg.time.values]   "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a4a0cc3-cb2e-4efb-9e86-eda65d31c079",
   "metadata": {},
   "source": [
    "## Create a Hindcast Ensemble in climpred for each of the models and run metrics\n",
    "\n",
    "We are also setting kwargs (options) for `verify` in climpred. The second cell does the metric calculation using `verify` and computes it. Finally all models are concatenated together and plotted.\n",
    "\n",
    "This could take a few minutes to run. If you are curious, check out the `dask` dashboard and you can watch the progress of the computations. The link should be like this: `https://jupyterhub.hpc.ucar.edu/stable/user/jaye/proxy/37030/status`. The number between proxy and status will vary. Your link will be available where you started your dask cluster in `cluster.ipynb`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fdb2cb2-2d9c-43d4-b108-565413e0d139",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ECMWF\n"
     ]
    }
   ],
   "source": [
    "he = {}\n",
    "met = {}\n",
    "hinds_state_dep ={}\n",
    "for h in hinds:\n",
    "    print(h)\n",
    "    hinds_state_dep=hinds\n",
    "    #hinds_state_dep[h]=hinds[h].sel(init=np.intersect1d(hinds[h].init,nao_pos.init))\n",
    "    he[h] = climpred.HindcastEnsemble(hinds_state_dep[h]).add_observations(verif)\n",
    "    if metric==\"rps\":\n",
    "        metric_kwargs = dict(metric=metric, comparison=comp, dim=dim, alignment=\"same_inits\")\n",
    "        met[h] = he[h].verify(category_edges=(verif_edges, hinds_edges[h]),**metric_kwargs)\n",
    "    else:\n",
    "        metric_kwargs = dict(metric=metric, comparison=comp, dim=dim, alignment=\"same_inits\", skipna=True)\n",
    "        met[h] = he[h].verify(**metric_kwargs)\n",
    "    met[h] = met[h].compute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9088093-46f1-4559-8017-f60ace4d536b",
   "metadata": {},
   "outputs": [],
   "source": [
    "met_all = xr.concat([met[models[0]], met[models[1]], met[models[2]]], dim='model') \\\n",
    "          .assign_coords(model=[models[0], models[1], models[2]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9017b4e-eb44-4369-b64a-e4fbe5a075be",
   "metadata": {},
   "outputs": [],
   "source": [
    "met_all[variable].plot(col='lead',row='model',cmap=cmap,robust=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6789ff8e-1667-44cd-aec7-df2fd8c4b931",
   "metadata": {},
   "source": [
    "## Seasonal data\n",
    "\n",
    "Now we will create seasonal averages of the data. Prior to this we have been looking at annual data. We use `groupby` here to group into seasons and then run `verify` over each of the seasons and models for the metric of our choice. They are then concatenated together and plotted for `lead=15` (weeks 3-4)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6e2caeb-09c6-4e40-94ce-542ab2f5c191",
   "metadata": {},
   "outputs": [],
   "source": [
    "groupby = \"season\"\n",
    "met_seas = {}\n",
    "for h in hinds:\n",
    "    met_groups = []\n",
    "    label_groups = []\n",
    "    # Loops through all inits for a given season.\n",
    "    for label_group, group in tqdm(he[h].get_initialized().groupby(f\"init.{groupby}\")):\n",
    "        # select only season inits\n",
    "        if metric==\"rps\":\n",
    "            met_group = he[h].sel(init=group.init).verify(category_edges=(verif_edges, hinds_edges[h]),**metric_kwargs)\n",
    "        else:\n",
    "            met_group = he[h].sel(init=group.init).verify(**metric_kwargs)\n",
    "        met_groups.append(met_group)\n",
    "        label_groups.append(label_group)\n",
    "    met_groups = xr.concat(met_groups, dim=groupby).assign_coords(season=label_groups)\n",
    "    met_seas[h] = met_groups.compute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "498a5714-d225-4d70-a92b-37825ce43fe0",
   "metadata": {},
   "outputs": [],
   "source": [
    "met_seas_all = xr.concat([met_seas[models[0]], met_seas[models[1]], met_seas[models[2]]], dim='model') \\\n",
    "               .assign_coords(model=[models[0], models[1], models[2]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "961da647-a167-432d-9611-ad1f0125797b",
   "metadata": {},
   "outputs": [],
   "source": [
    "met_seas_all.sel(lead=15)[variable].plot(col=groupby, row='model', robust=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e456f5d-74fa-4b3b-b228-af12d18b4b48",
   "metadata": {},
   "source": [
    "## Area weighting\n",
    "\n",
    "Next we run cosine area weighting over that data to get a weighted lat/lon average over the domain. We then print out the weights and plot them on bar charts to compare different seasons and models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a76f980c-76eb-443a-af54-35d5b55707a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "weight = met_seas_all.weighted(np.cos(np.deg2rad(met_seas_all.lat))).mean((\"lat\", \"lon\"))[variable].drop('skill')\n",
    "weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "092a4e83-03ca-49ff-9466-4e54f827832f",
   "metadata": {},
   "outputs": [],
   "source": [
    "seasons = np.array(weight.season)\n",
    "barWidth = 0.25\n",
    "rw = np.arange(3)\n",
    "rw1 = [x + barWidth + 0.025 for x in rw]\n",
    "rw2 = [x + barWidth + 0.025 for x in rw1]\n",
    "if weight.min() < 0.:\n",
    "    ymin = weight.min()*0.6+weight.min()\n",
    "else:\n",
    "    ymin = 0.0\n",
    "ymax = weight.max()*0.6+weight.max()\n",
    "for s in seasons:\n",
    "    plt.bar(rw,weight.sel(season=s,model=models[0]), width = barWidth, color = (0, 0.4470, 0.7410), edgecolor=\"white\",label=models[0])\n",
    "    plt.bar(rw1,weight.sel(season=s,model=models[2]), width = barWidth, color = (0.6350, 0.0780, 0.1840), alpha=0.8,edgecolor=\"white\",label=models[2])\n",
    "    plt.bar(rw2,weight.sel(season=s,model=models[1]), width = barWidth, color = (0.4, .75, 0.1), alpha=0.8,edgecolor=\"white\",label=models[1])\n",
    "    plt.xticks([r + barWidth + 0.025 for r in range(3)], [\"Weeks 1-2\", \"Weeks 3-4\", \"Weeks 5-6\"],fontsize=15)\n",
    "    plt.ylim(ymin,ymax)\n",
    "    plt.ylabel(metric.upper(),fontsize=18,fontweight=\"bold\")\n",
    "    plt.xlabel(\"Week\",fontsize=18,fontweight=\"bold\")\n",
    "    plt.grid()\n",
    "    plt.legend(borderaxespad=0.6,edgecolor=\"black\",prop={'size': 15},loc=\"upper right\")\n",
    "    plt.title(variable.upper()+\" \"+metric.upper()+\" for season = \"+s,fontsize=18,fontweight=\"bold\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a86c1fd7-1e48-47dc-aa0c-a0d442c173f9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aad151dd-64db-4f04-beb9-5f768e923f2f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "s2s-asp",
   "language": "python",
   "name": "s2s-asp"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
